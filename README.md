
üöÄ**Supervised Learning With Scikit-Learn - Datacamp**üöÄ


Reposit√≥rio destinado para anota√ß√µes e teste de c√≥digo das aulas do curso Supervised Learning with scikit-learn do DataCamp. A maioria dos c√≥digos s√£o executados na pr√≥pria ferramenta, mas achei v√°lido testar algumas coisas localmente para melhor compreens√£o. 


üìä **O curso aborda**:
- **Cria√ß√£o de Modelos Preditivos**: Desenvolvimento de modelos para prever se um cliente vai deixar um servi√ßo, identificar se um indiv√≠duo tem diabetes e at√© classificar o g√™nero de uma m√∫sica. Al√©m da cria√ß√£o de Pipelines, utilizando o scikit, para Normaliza√ß√£o dos dados e transforma√ß√£o com imputers.
- **Otimiza√ß√£o e Avalia√ß√£o**: no curso √© trabalhado exaustivamento a utiliza√ß√£o da valida√ß√£o cruzadada e √© desenvolvido fine-tuning de param√¢metros dos modelos utilizando GridSearch e RandomSearch.

**Algumas discuss√µes interessantes:**

- **Intui√ß√£o do fine-tunind do par√¢metro n_neighbors (n√∫mero de vizinhos) do modelo k-nearest neighbors (knn):**

 O par√¢metro √© utilizado para definir o n√∫mero de vizinhos que ser√£o avaliados para definir a classe do novo ponto de dados, quanto maior esse n√∫mero, mais o modelo se torna complexo, podendo em alguns casos melhorar a performance, mas em outros levar ao overfiting. A imagem abaixo mede a acur√°cia em difentes n√∫meros de vizinhos para um modelo de classifica√ß√£o treinado e testado no dataset Iris do scikit-learn. 

(images/knn.png)

- **Utilizar o Mean Squared Error Negativo na valida√ß√£o cruzada:**

A valida√ß√£o cruzada tem como padr√£o escolher o maior valor na fun√ß√£o de custo, o que √© errado quando estamos usando a m√©trica Mean Squared Error que quanto menor √© melhor, nesse caso para obtermos o melhor modelo podemos utilizar o Mean Squared Error negativo. Exemplo de aplica√ß√£o: 
```python 
# Create X and y
X = music_dummies.drop('popularity',axis=1).values
y = music_dummies['popularity'].values

#¬†Instantiate a ridge model
ridge = Ridge(alpha=0.2)

#¬†Perform cross-validation
scores = cross_val_score(ridge, X, y, cv=kf, scoring="neg_mean_squared_error")

#Calculate RMSE
rmse = np.sqrt(-scores)
print("Average RMSE: {}".format(np.mean(rmse)))
print("Standard Deviation of the target array: {}".format(np.std(y)))

